# Job
job.factory.class=org.apache.samza.job.yarn.YarnJobFactory
job.name=dev.publish.pipeline

# YARN
yarn.package.path=file://${basedir}/target/${project.artifactId}-${pom.version}-distribution.tar.gz

# Metrics
metrics.reporters=snapshot,jmx
metrics.reporter.snapshot.class=org.apache.samza.metrics.reporter.MetricsSnapshotReporterFactory
metrics.reporter.snapshot.stream=kafka.dev.lp.metrics
metrics.reporter.jmx.class=org.apache.samza.metrics.reporter.JmxReporterFactory

# Task
task.class=org.ekstep.jobs.samza.task.PublishPipelineTask
#task.inputs=kafka.telemetry.raw
task.inputs=kafka.local.learning.job.request
task.checkpoint.factory=org.apache.samza.checkpoint.kafka.KafkaCheckpointManagerFactory
task.checkpoint.system=kafka
task.checkpoint.replication.factor=1
task.commit.ms=60000
#task.opts=-agentlib:jdwp=transport=dt_socket,address=localhost:9009,server=y,suspend=y
task.window.ms=300000

# Serializers
serializers.registry.json.class=org.ekstep.jobs.samza.serializers.EkstepJsonSerdeFactory
serializers.registry.metrics.class=org.apache.samza.serializers.MetricsSnapshotSerdeFactory

# Systems
systems.kafka.samza.factory=org.apache.samza.system.kafka.KafkaSystemFactory
systems.kafka.samza.msg.serde=json
systems.kafka.streams.metrics.samza.msg.serde=metrics
systems.kafka.consumer.zookeeper.connect=localhost:2181
systems.kafka.consumer.auto.offset.reset=largest
systems.kafka.producer.bootstrap.servers=localhost:9092

# Job Coordinator
job.coordinator.system=kafka
# Normally, this would be 3, but we have only one broker.
job.coordinator.replication.factor=1

# Job specific config properties
graph.dir="/data/graphDB"
redis.host=localhost
redis.port=6379
redis.maxConnections=128
akka.request_timeout=30
environment.id=10000000
graph.ids=domain
graph.passport.key.base="31b6fd1c4d64e745c867e61a45edc34a"
route.domain="bolt://localhost:7687"
route.bolt.write.domain="bolt://localhost:7687"
route.bolt.read.domain="bolt://localhost:7687"
route.bolt.comment.domain="bolt://localhost:7687"
route.all="bolt://localhost:7687"
route.bolt.write.all="bolt://localhost:7687"
route.bolt.read.all="bolt://localhost:7687"
route.bolt.comment.all="bolt://localhost:7687"
shard.id=1
platform.auth.check.enabled=false
platform.cache.ttl=3600000
backend_telemetry_topic=local.telemetry.backend
failed_event_topic=local.learning.job.request
#S3 server configurations

#Environment specific buckets
s3.public.bucket=ekstep-public-dev

#S3 Region configuration
s3.region = AP_SOUTH_1

#Folder configuration
s3.content.folder=content
s3.asset.folder=assets
s3.artifact.folder=artifact
s3.bundle.folder=bundle
s3.media.folder=media
s3.ecar.folder=ecar_files

s3.upload.url.expiry = 600

#Envionment specific URL prefix
s3.url.dev=https://dev.ekstep.in
s3.url.qa=https://qa.ekstep.in
s3.url.prod=https://community.ekstep.in
s3.url.sandbox=https://sandbox.ekstep.in

#directory location where store unzip file
dist.directory = /data/tmp/dist/
output.zipfile = /data/tmp/story.zip
source.folder  = /data/tmp/temp2/
save.directory = /data/tmp/temp/

MAX_CONTENT_PACKAGE_FILE_SIZE_LIMIT = 52428800
MAX_ASSET_FILE_SIZE_LIMIT = 20971520
RETRY_ASSET_DOWNLOAD_COUNT = 1

cassandra.host=localhost
cassandra.port=9042

lp.tempfile.location=__lp_tmpfile_location__
publish.collection.fullecar.disable=true
max.iteration.count.samza.job=2
publish.content.limit=200

#Remote Debug Configuration 
#task.opts=-agentlib:jdwp=transport=dt_socket,address=localhost:9009,server=y,suspend=y

# Metrics
output.metrics.job.name=publish-pipeline
output.metrics.topic.name=__env__.pipeline_metrics

#Failed Topic Config
output.failed.events.topic.name=local.learning.job.request.fail