# Job
job.factory.class=org.apache.samza.job.yarn.YarnJobFactory
job.name=__env__.word-enrichment

# YARN
yarn.package.path=http://__yarn_host__:__yarn_port__/__env__/${project.artifactId}-${pom.version}-distribution.tar.gz


# Metrics
metrics.reporters=snapshot,jmx
metrics.reporter.snapshot.class=org.apache.samza.metrics.reporter.MetricsSnapshotReporterFactory
metrics.reporter.snapshot.stream=kafka.__env__.metrics
metrics.reporter.jmx.class=org.apache.samza.metrics.reporter.JmxReporterFactory

# Task
task.class=org.ekstep.jobs.samza.task.WordEnrichmentTask
task.inputs=kafka.__env__.learning.graph.events
task.checkpoint.factory=org.apache.samza.checkpoint.kafka.KafkaCheckpointManagerFactory
task.checkpoint.system=kafka
task.checkpoint.replication.factor=1
task.commit.ms=60000

# Serializers
serializers.registry.json.class=org.ekstep.jobs.samza.serializers.EkstepJsonSerdeFactory
serializers.registry.metrics.class=org.apache.samza.serializers.MetricsSnapshotSerdeFactory

# Systems
systems.kafka.samza.factory=org.apache.samza.system.kafka.KafkaSystemFactory
systems.kafka.samza.msg.serde=json
systems.kafka.streams.metrics.samza.msg.serde=metrics
systems.kafka.consumer.zookeeper.connect=__zookeepers__
systems.kafka.consumer.auto.offset.reset=smallest
systems.kafka.samza.offset.default=oldest
systems.kafka.producer.bootstrap.servers=__kafka_brokers__

# Job Coordinator
job.coordinator.system=kafka
# Normally, this would be 3, but we have only one broker.
job.coordinator.replication.factor=1

# Job specific config properties
language-api-url=__language_url__
ekstepPlatformApiUserId=ilimi

# Job specific config properties
redis.host=__redis_host__
redis.port=__redis_port__
redis.maxConnections=128
akka.request_timeout=30
environment.id=__environment_id__
graph.passport.key.base=__graph_passport_key__
route.domain=__lp_bolt_url__
route.bolt.read.domain=__lp_bolt_read_url__
route.bolt.write.domain=__lp_bolt_write_url__
route.all=__other_bolt_url__
route.bolt.read.all=__other_bolt_read_url__
route.bolt.write.all=__other_bolt_write_url__
shard.id=__mw_shard_id__
graph.dir="/data/graphDB"
graph.ids=["domain","language","as","bn","en","gu","hi","hoc","jun","ka","mai","mr","unx","or","san","sat","ta","te","urd"]
platform.auth.check.enabled=false
platform.cache.ttl=3600000


#language-indexes 
elastic-search-host=http://__es_host__
elastic-search-port=__es_port__
ignoreStartWordsList=["<Sentence","id=","<fs","head=","case_name=","paradigm=","name=","inf="]
tagNamesList=["NN","NST","PRP","DEM","VM","VAUX","JJ","RB","PSP","RP","CC","WQ","QF","QC","QO","CL","INTF","INJ","NEG","*C","RDP","ECH","UNK","NP","VGF","VGNF","VGINF","VGNN","JJP","RBP","NEGP","CCP","FRAGP","BLK"]
discardTokensList=["NNP","((","))","SYM"]
attributesTagIdentifier=af
specialCharRegEx="^([$&+,:;=?@#|!]*)$"
numberRegEx="^([+-]?\\d*\\.?\\d*)$"
defaultTokenCountAfterWord=10

#language-map
hi=Hindi
en=English
te=Telugu
ka=Kannada
ta=Tamil
as=Assamese
bn=Bengali
bo=Bodo
gu=Gujarati
ko=Konkani
ml=Malayalam
mr=Marathi
ne=Nepali
or=Odia
pa=Punjabi
sa=Sanskrit